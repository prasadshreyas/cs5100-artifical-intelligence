{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d145e55-7382-4e1f-bb5c-560d5fac0d0e",
   "metadata": {},
   "source": [
    "# Maze: Q-Learning\n",
    "\n",
    "    Install Dependencies:\n",
    "```python\n",
    "!pip install gym\n",
    "!pip install pygame\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dda08d5f-1f9c-48f6-8093-e641a028a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries and dependencies\n",
    "import gym\n",
    "import MazeEnv\n",
    "import random\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "46564fdb-2deb-44e1-9390-6a9062190dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Gym-env\n",
    "env=gym.make('maze-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f759be7c-4162-4d75-b3bf-119b6f06cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing hyperparameters\n",
    "alpha = 0.5\n",
    "gamma = 0.75\n",
    "reward_final=0\n",
    "random_state = np.random.RandomState(100)\n",
    "eps = 0.06\n",
    "curr_state=0\n",
    "env.reset()\n",
    "flag=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d33d9315-aef0-4380-a125-a79e27b6000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Q-Table\n",
    "q_table = np.zeros((6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "425ea83a-0500-4002-a58d-bca3abceb97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the rewards matrix\n",
    "reward_table = np.array([[-1, -1, -1, -1, 0, -1],\n",
    "                        [-1, -1, -1, 0, -1, 100],\n",
    "                        [-1, -1, -1, 0, -1, -1],\n",
    "                        [-1, 0, 0, -1, 0, -1],\n",
    "                        [0, -1, -1, 0, -1, 100],\n",
    "                        [-1, 0, -1, -1, 0, 100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aed4b2cf-d480-43e6-a799-7238716dbeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Q-Table\n",
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "Rewards Matrix\n",
      "[[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial Q-Table\")\n",
    "print(q_table)\n",
    "\n",
    "print(\"Rewards Matrix\")\n",
    "print(reward_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "64ede85e-bb3c-45af-a40f-ca967ad3100d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2\n",
      "Next possible states: [3]\n",
      "In 3 , Next Action:3 to 3\n",
      "Reward: 0\n",
      "In 3\n",
      "Next possible states: [1 2 4]\n",
      "In 1 , Next Action:1 to 1\n",
      "Reward: 0\n",
      "In 1\n",
      "Next possible states: [3 5]\n",
      "In 1 , Next Action:0 to 1\n",
      "Reward: 0\n",
      "In 1\n",
      "Next possible states: [3 5]\n",
      "In 1 , Next Action:1 to 1\n",
      "Reward: 0\n",
      "In 1\n",
      "Next possible states: [3 5]\n",
      "In 1 , Next Action:4 to 1\n",
      "Reward: 0\n",
      "In 1\n",
      "Next possible states: [3 5]\n",
      "In 1 , Next Action:1 to 1\n",
      "Reward: 0\n",
      "In 1\n",
      "Next possible states: [3 5]\n",
      "In 1 , Next Action:4 to 1\n",
      "Reward: 0\n",
      "In 1\n",
      "Next possible states: [3 5]\n",
      "In 3 , Next Action:3 to 3\n",
      "Reward: 0\n",
      "In 3\n",
      "Next possible states: [1 2 4]\n",
      "In 3 , Next Action:0 to 3\n",
      "Reward: 0\n",
      "In 3\n",
      "Next possible states: [1 2 4]\n",
      "In 2 , Next Action:2 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 2 , Next Action:5 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 3 , Next Action:3 to 3\n",
      "Reward: 0\n",
      "In 3\n",
      "Next possible states: [1 2 4]\n",
      "In 1 , Next Action:1 to 1\n",
      "Reward: 0\n",
      "In 1\n",
      "Next possible states: [3 5]\n",
      "In 3 , Next Action:3 to 3\n",
      "Reward: 0\n",
      "In 3\n",
      "Next possible states: [1 2 4]\n",
      "In 3 , Next Action:0 to 3\n",
      "Reward: 0\n",
      "In 3\n",
      "Next possible states: [1 2 4]\n",
      "In 2 , Next Action:2 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 2 , Next Action:1 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 2 , Next Action:2 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 2 , Next Action:0 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 2 , Next Action:4 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 2 , Next Action:2 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 2 , Next Action:4 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 2 , Next Action:2 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 2 , Next Action:5 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 2 , Next Action:2 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 2 , Next Action:2 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 2 , Next Action:0 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 2 , Next Action:0 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 2 , Next Action:1 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 2 , Next Action:2 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 2 , Next Action:1 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 2 , Next Action:1 to 2\n",
      "Reward: 0\n",
      "In 2\n",
      "Next possible states: [3]\n",
      "In 3 , Next Action:3 to 3\n",
      "Reward: 0\n",
      "In 3\n",
      "Next possible states: [1 2 4]\n",
      "In 3 , Next Action:0 to 3\n",
      "Reward: 0\n",
      "In 3\n",
      "Next possible states: [1 2 4]\n",
      "In 4 , Next Action:4 to 4\n",
      "Reward: 0\n",
      "In 4\n",
      "Next possible states: [0 3 5]\n",
      "In 5 , Next Action:5 to 5\n",
      "Reward: 100\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    states = list(range(6))\n",
    "    random_state.shuffle(states)\n",
    "    if flag == False:\n",
    "            #action = np.argmax(q_table[state])\n",
    "            #env.render()\n",
    "            legal = reward_table[env.state] >= 0\n",
    "            actions = np.array(list(range(6)))\n",
    "            legal_actions = actions[legal == True]\n",
    "            print('In', env.state)\n",
    "            print(\"Next possible states:\", legal_actions)\n",
    "            if random_state.rand() < eps:\n",
    "                action = int(legal_actions[0])\n",
    "            else:\n",
    "                if np.sum(q_table[env.state]) > 0:\n",
    "                    action = np.argmax(q_table[env.state])\n",
    "                else:\n",
    "                    action = env.actions[int(random.random() * len(env.actions))]\n",
    "            next_state, r, is_terminal, info = env.step(action)\n",
    "            if r >0:\n",
    "                reward_final += r\n",
    "            print(\"In \" + str(env.state), \", Next Action:\" + str(action) + \" to \" + str(next_state))\n",
    "            print(\"Reward:\", reward_final)\n",
    "            \n",
    "            reward = reward_table[env.state, next_state]\n",
    "            compute = reward + gamma * max(q_table[next_state, :])\n",
    "            q_table[env.state, next_state] = compute\n",
    "\n",
    "            if is_terminal == True:\n",
    "                curr_state=next_state\n",
    "                flag=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2f576320-fd6e-4db4-9c6b-e36e085514fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final state: 5\n",
      "\n",
      "Final reward: 100\n"
     ]
    }
   ],
   "source": [
    "print('Final state:',curr_state)\n",
    "print()\n",
    "print(\"Final reward:\", reward_final)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
